<html>
<head>
<title>'Hey Google' is no longer the only way to talk to Google Assistant</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>“嘿，谷歌”不再是与谷歌助手交流的唯一方式</h1>
<blockquote>原文：<a href="https://www.xda-developers.com/new-google-assistant-features-google-io/#0001-01-01">https://www.xda-developers.com/new-google-assistant-features-google-io/#0001-01-01</a></blockquote><div><header class="article_heading">


<h1 class="heading_title">“嘿，谷歌”不再是与谷歌助手交流的唯一方式</h1>

<p class="heading_sharing">  </p>


<p class="heading_excerpt">在Nest Hub Max上与谷歌助手互动将变得更加容易。再也不需要“嘿谷歌”了。</p>



  </header>

<section id="article-body" class="article-body" itemprop="articleBody">

<div class="content-block-regular">
<p>在今天的Google I/O大会上，关于我们未来将如何与Google Assistant互动的重大变化已经揭晓。也许对大多数人来说，最大的变化是你不再需要说“嘿谷歌”来触发助手。这是之前谣传的，但是谷歌现在已经正式宣布了。</p>

  
<p>Nest Hub Max的所有者将从今天开始在美国看到新的选择。第一种叫做看和说，它的操作和听起来一模一样。你只要看着Nest Hub Max就开始说话。该设备将使用面部匹配和声音匹配来识别您，因此您仍然可以获得个性化的结果，并且所有处理都完全在本地完成。这些面部识别数据都不会被发送到云端，这是一项自愿加入的服务。</p>



<p>第二个是快速短语，扩展了你与谷歌助手的互动方式。同样，它放弃了使用熟悉的触发短语的需要，但你将能够做一些事情，如设置定时器，询问时间，或打开和关闭你的灯。</p>

<p>与此同时，谷歌助手理解你的方式也有所改善。Assistant现在在理解自然语言方面更加智能，包括那些我们经常遇到的嗯和错误。语音模型被移动到设备上以加快处理速度。这一突破是通过在谷歌张量芯片上构建更好的神经网络实现的。</p>

<section class="emaki-custom-block emaki-custom-pullquote"><div class="emaki-custom pullquote" id="custom_block_5"><p>展望未来，Assistant将能够更好地理解人类语言的不完美之处，而不会出错——包括停顿、“嗯嗯”和打断——使您的交互感觉更接近自然对话。</p> </div></section>
<p>在舞台上使用的例子是要求一首歌，但暂停，不太知道完整的艺术家的名字。谷歌助手现在足够聪明，可以理解演讲和停顿，并找出缺失的部分。</p>

 </div>


<p id="article-waypoint"/>
</section>


        </div>    
</body>
</html>